File Structure:
    * in tvm compiler device:
        data/
          - FashionMNIST/  (it can be downloaded in data_process.py)            
        data_process.py
        _gradient.py
        utils.py
        mod_export.py
    * in cpp compiler device:
        include/
        cpp_demo_mlp.cc
        libtvm_runtime.so
    * in training device
        data/
          - fanshionMNIST_data_label
          - fanshionMNIST_data_x
        mlp_mod (bin)
        libtvm_runtime.so
        mlp_mod.so

Env Setting:
    * add this directory to LD_LIBRARY_PATH
    * add include/ to CPATH

Use g++ to compile demo:
    * g++ cpp_demo_mlp.cc -L. -ltvm_runtime -o mlp_mod

How to run:
    1. Run data_process.py to get the cpp-friendly data. (binary files fanshionMNIST_data_*)
    2. Use tvm (with relax AD version) to compile and export the mod. (mlp_mod.so)
    3. Prepare the tvm runtime. (libtvm_runtime.so)
    4. Use g++ to compile the cpp_demo_mlp.cc and get bin (mlp_mod).
    5. Run it in training device.